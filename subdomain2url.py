#!/usr/bin/env python2
# encoding: utf8

"""
    author: jlz
    date: 20170403
    use: process file with subdomains, convert to urls
    example: www.baidu.com -> http://www.baidu.com/
"""


import os
import sys
import time
import json
import argparse
import traceback
import string
import itertools
import dns.resolver
from dns.resolver import NoAnswer, NXDOMAIN

import requests
import threading
import Queue
import gevent
from gevent import monkey
monkey.patch_all()


def start_thread_as_daemon(target, args):
    t = threading.Thread( target=target, args=args )
    t.daemon = True
    t.start()
    return t

job_queue = Queue.Queue( 1024*8 )
def job_distribute( subdomains ):
    global job_queue

    for subdomain in subdomains:
        job_queue.put( subdomain )


success_queue = Queue.Queue( 512 )
def success_log():
    global success_queue
    while True:
        s = success_queue.get()
        print s

def job_worker():
    global job_queue
    while True:

        job = job_queue.get()
        subdomain = job

        # first, test http
        for scheme in ['http', 'https']:
            try:
                url = '{}://{}'.format( scheme, subdomain )
                r = requests.get( url, allow_redirects=True, timeout=3 )
                success_queue.put( r.url )
            except Exception as e:
                sys.exc_clear()

def main():
    # Parse command line options
    parser = argparse.ArgumentParser()
    parser.add_argument("-f", "--file", type=str, required=True, help="subdomain file to scan")
    parser.add_argument("-t", "--thread", type=int, required=False, default=256, help="threads to use")
    args = parser.parse_args()

    with open( args.file, 'rb' ) as fin:
        lines = fin.read().split( '\n' )
    subdomains = map( lambda x:x.strip(), filter( None, lines ) )
    subdomains = map( lambda x:json.loads(x), subdomains )
    subdomains = map( lambda x:x[0], subdomains )

    start_thread_as_daemon( target=job_distribute, args=[subdomains,] )
    start_thread_as_daemon( target=success_log, args=[] )
    time.sleep( 1 )

    gevent_routine_list = []
    max_gevent_routine = args.thread

    for routine_index in xrange(max_gevent_routine):

        gevent_routine_list.append( gevent.spawn( job_worker ) )

    while True:
        print 'job_queue size:', job_queue.qsize()
        time.sleep( 3 )

if __name__ == '__main__':
    main()
