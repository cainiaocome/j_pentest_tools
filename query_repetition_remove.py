"""
    author: jlz
    date: 2017-03-31
    what does this script do: iterate over url, and remove those url whose query parameters has already seen in other urls.for example:
    url_1: http://www.baidu.com/s?key=123&date=2017
    url_2: http://www.baidu.com/s?key=456
    since in url_1 has a query parameter named key, url_2 will be removed.
"""
import os
import sys
reload(sys)
sys.setdefaultencoding('utf-8')
import time
import json
import Queue
import traceback
import urlparse
import argparse
from pprint import pprint, pformat


# so, this is a dict, like this
# {
#     "www.baidu.com": ['search_key', 'date'],
#     'www.qq.com':['qq', 'age'],
# }
netloc_querykeyset_dict = {}

def hash_url( url ):
    global netloc_querykeyset_dict

    this_url = urlparse.urlparse( url )
    this_url_netloc = this_url.netloc
    this_url_querykeyset = set(urlparse.parse_qs( this_url.query ).keys())

    already_met_querykeyset = netloc_querykeyset_dict.get( this_url_netloc, set() )

    if this_url_querykeyset <= already_met_querykeyset:
        return False
    else:
        already_met_querykeyset.update( this_url_querykeyset )
        netloc_querykeyset_dict.setdefault( this_url_netloc, already_met_querykeyset )
        return True
    
def main():
    with open( sys.argv[1], 'rb' ) as fin:
        lines = fin.read().split('\n')
    to_process_urls = filter( None, lines )

    for url in to_process_urls:

        if hash_url( url ):

            print url

if __name__ == '__main__':
    main()
